# Sign Language Recognition Using OpenCV

This project focuses on recognizing sign language gestures using OpenCV, Tensorflow, and Keras. It provides a practical implementation of region of interest (ROI) detection to capture and interpret sign language gestures.

## Dependencies

Make sure you have the following dependencies installed:

1. [Tensorflow](https://www.tensorflow.org/)
2. [Keras](https://keras.io/)
3. [OpenCV](https://opencv.org/)

## Dataset

The project utilizes the Sign Language MNIST dataset, which can be found on Kaggle: [Sign Language MNIST Dataset](https://www.kaggle.com/datamunge/sign-language-mnist)

## Tools

This project leverages Google Colab for collaborative development and execution. You can use Colab notebooks to run and experiment with the code seamlessly.

## How to Run

To run the project, follow these steps:

1. Clone the repository to your local machine.
2. Install the required dependencies (Tensorflow, Keras, OpenCV).
3. Download the Sign Language MNIST dataset from Kaggle and place it in the appropriate directory.
4. Open and run the `ROIinOpenCV.py` script to execute the sign language recognition using OpenCV.

## PyTorch Implementation

For an alternative implementation using PyTorch, check out the `sign_language_pytorch.ipynb` notebook provided in the project. This notebook contains the PyTorch-based code for sign language recognition.

Feel free to explore and modify the code to suit your specific needs and enhance the project further.

---
